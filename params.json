{"name":"BitTroll","tagline":"BitTorrent Search Engine","body":"# BitTroll\r\n\r\nBitTroll is an open source BitTorrent DHT scraper and search engine. BitTroll listens\r\nto the BitTorrent Mainline DHT for torrent info hashes and then tries to resolve the\r\ntorrent's metadata (file names, torrent titles, file sizes, etc) to store for purposes of indexing/searching.\r\n\r\nBitTroll works on Debian/Ubuntu/Fedora/Mac OS X but can be easily adapted to work on Windows (this is planned for the future).\r\n\r\nBitTroll can scrape from cache services like torcache.net for torrent files for info hashes it wishes to resolve.\r\n\r\nBitTroll attempts to classify torrents into categories using a basic classification algorithm.\r\n\r\nBitTroll can be store data in either MySQL or SQLite3 (default).\r\n\r\nBitTroll can serve a web UI to search torrent data and/or serve a RESTful API to access the data.\r\n\r\n## Dependencies\r\n\r\nOn Debian/Ubuntu/Linux Mint/Fedora/Mac OS, the dependencies can be installed\r\nwith the `prereqs.sh` script or by running `make prereqs`.\r\n\r\n* Python\r\n* Flask\r\n* Tornado\r\n* Requests\r\n* libtorrent-rasterbar\r\n* Python bindings for libtorrent-rasterbar\r\n\r\n## Configuration\r\nConfiguration is stored in `config.json` file. See `config.sample.json` for full detail.\r\nCopy `config.sample.json`, save as `config.json`, and configure to your needs.\r\n\r\n### Database\r\nFor the database, SQLite3 is used if no database setting is found. When specifying a\r\ndatabase to use, only put that entry in (only `mysql` or `sqlite3`).\r\n\r\nBitTroll will create the database structure when `--init` is passed on the command line.\r\n**Database needs to be initialized before BitTroll can start.**\r\n\r\n#### Sample SQLite3 Configuration\r\n**config.json**\r\n```\r\n{\r\n  \"db\":\r\n  {\r\n    \"sqlite3\": \"database.s3db\"\r\n  }\r\n}\r\n```\r\n\r\n#### Sample MySQL Configuration\r\n**config.json**\r\n```\r\n{\r\n  \"db\":\r\n  {\r\n    \"mysql\": {\r\n      \"host\": \"127.0.0.1\",\r\n      \"user\": \"metadata\",\r\n      \"passwd\": \"password\",\r\n      \"db\": \"metadata\"\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n### Scraping from Caches\r\nBitTroll can scrape torrent files from torrent caching services like torcache.net and btcache.me.\r\n\r\n#### Sample Scraping Configuration\r\nIn this configuration both torcache.net and btcache.me are scraped for torrent files\r\nwe're trying to resolve.\r\n\r\n**config.json**\r\n```\r\n{\r\n  \"scrape_caches\": [\r\n    {\r\n      \"name\": \"torcache\",\r\n      \"enabled\": true,\r\n      \"pull_url\": \"http://torcache.net/torrent/<info_hash>.torrent\",\r\n      \"push_url\": \"\"\r\n    },\r\n    {\r\n      \"name\": \"btcache\",\r\n      \"enabled\": true,\r\n      \"pull_url\": \"http://btcache.me/torrent/<info_hash>\",\r\n      \"push_url\": \"\"\r\n    }\r\n  ]\r\n}\r\n```\r\n\r\n`<info_hash>` is the placeholder in the url for the info hash. Different torrent\r\ncache services will have different url patterns.\r\n\r\n### Push To\r\nThis allows nodes to share torrent metadata without sharing a common database.\r\nThis feature allows the pushing node (sender) to share metadata\r\nto receiving node by calling a RESTful API endpoint on the receiving node.\r\n\r\nTwo or more nodes could all be configured to share with each other and therefore\r\nbe synchronized. However, this is not the preferred way of synchronizing across nodes as\r\nwill only synchronize torrent file metadata (torrent files, torrent titles, torrent file names/sizes)\r\nbut not node generated data (torrent categories, seed/leech counts). If possible, a more efficient\r\nsolution for keeping nodes synchronized is by configuring all nodes to use a common\r\nMySQL server/cluster.\r\n\r\nThat being said, the push feature was designed for friends/collaborators to expand their\r\ntorrent databases by pushing to each others nodes/clusters. Additionally, two collaborators\r\ncould have seperate BitTroll clusters and use the push feature to share between their clusters.\r\n\r\n**Note:** The push/pull communication is over HTTP and therefore not encrypted. This is\r\nnot necessarily a problem on a local network (LAN). In either case the traffic can be\r\nintercepted along it's route from node to node (especially if the nodes are communicating over the internet).\r\nAuthentication keys will be transferred plain-text and can be intercepted in this scenario.\r\nOne way to enable encryption is to use HTTPS, the best way to accomplish this is to put\r\nthe RESTful API behind nginx (with SSL enabled).\r\n\r\n#### Sample Push Configuration\r\nIn this configuration node 1 (pushing node) will contact node 2 (receiving node) every 300 seconds\r\nand present a list of info hashes it has torrent files for.\r\nNode 2 will respond to node 1 with all the info hashes from that list that it would like.\r\nFinally, node 1 will then push all the requested torrent files to node 2.\r\n\r\n##### Node 1 - Pushing / Sending node\r\n**config.json**\r\n```\r\n{\r\n  \"share\":\r\n  {\r\n    \"push_to\": [\r\n      {\r\n        \"auth\": \"ABCDEFGHIJ\",\r\n        \"url\": \"http://192.168.1.100:11000/torrents/push\",\r\n        \"period\": 300\r\n      }\r\n    ]\r\n  }\r\n}\r\n```\r\n\r\n##### Node 2 - Pulling / Receiving node\r\n**config.json**\r\n```\r\n{\r\n  \"share\":\r\n  {\r\n    \"authorized\":\r\n    {\r\n      \"ABCDEFGHIJ\": { \"push\": true },\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n### Web UI\r\nThe Web UI supplied in BitTroll is contained in a single `index.html` file. It uses the\r\nRESTful API to communicate with the BitTroll backend. The `index.html` file is in the `templates`\r\nfolder and could be easily replaced with something to suit your needs. Additionally, custom\r\nweb interfaces can be written to utilize BitTroll's RESTful API.\r\n\r\n## Running\r\nSee command line help with `python main.py -h`.\r\n\r\nTo start BitTroll with Metadata scraping, RESTful API, and Web UI:\r\n\r\n1. `python main.py --init`\r\n\r\n2. `python main.py`\r\n\r\nTo start in the background, after database is initialized:\r\n\r\n`./start.sh`\r\n\r\nTo stop:\r\n\r\n`./stop.sh`\r\n\r\nThe default web ui location is `http://127.0.0.1:11000`\r\n\r\n### Running a cluster\r\n\r\n#### Sample Cluster - Single Web UI / Multiple Scrape Nodes\r\nIn this deployment we will run a single web ui and multiple nodes to scrape for\r\ntorrent metadata. The simplest setup will use a single MySQL server.\r\n\r\n##### Node 1 - Web UI\r\n**config.json**\r\n```\r\n{\r\n  \"host\": \"0.0.0.0\",\r\n  \"webui\": true,\r\n  \"scrape\": false,\r\n  \"db\":\r\n  {\r\n    \"mysql\": {\r\n      \"host\": \"192.168.1.100\",\r\n      \"user\": \"metadata\",\r\n      \"passwd\": \"password\",\r\n      \"db\": \"metadata\"\r\n    }\r\n  }\r\n}\r\n```\r\n\r\nThis will start the web ui on this machine, binding to all network interfaces.\r\n\r\n##### Node 2 & 3 - Scrape nodes\r\n**config.json**\r\n```\r\n{\r\n  \"webui\": false,\r\n  \"api\": false,\r\n  \"scrape\": true,\r\n  \"db\":\r\n  {\r\n    \"mysql\": {\r\n      \"host\": \"192.168.1.100\",\r\n      \"user\": \"metadata\",\r\n      \"passwd\": \"password\",\r\n      \"db\": \"metadata\"\r\n    }\r\n  }\r\n}\r\n```\r\n\r\nThis will start the metadata scraping for these two nodes. They will store all torrents\r\nthey find metatdata for into the MySQL database for the web ui to search through.\r\n\r\n#### Sample Cluster - Multiple Web UI / Scrape Nodes\r\nIn this deployment we will run several identical instances that will serve as both\r\nweb ui and metadata scrapers. We will use a single MySQL database. The idea behind\r\nhaving multiple machines serve the UI is to load balance (e.g. nginx).\r\n\r\n##### Nodes 1, 2, 3\r\n**config.json**\r\n```\r\n{\r\n  \"host\": \"0.0.0.0\",\r\n  \"webui\": true,\r\n  \"api\": true,\r\n  \"scrape\": true,\r\n  \"db\":\r\n  {\r\n    \"mysql\": {\r\n      \"host\": \"192.168.1.100\",\r\n      \"user\": \"metadata\",\r\n      \"passwd\": \"password\",\r\n      \"db\": \"metadata\"\r\n    }\r\n  }\r\n}\r\n```\r\n\r\nThis will start the web ui and scraping on each node.\r\n\r\nA sample load balancing nginx configuration would look like:\r\n\r\n```\r\nhttp {\r\n    upstream bittroll_webuis {\r\n        # Node 1\r\n        server 192.168.1.100:11000;\r\n\r\n        # Node 2\r\n        server 192.168.1.101:11000;\r\n\r\n        # Node 3\r\n        server 192.168.1.102:11000;\r\n    }\r\n\r\n    server {\r\n        listen 80;\r\n        server_name mybittorrentsearchengine.com\r\n\r\n        index index.html;\r\n\r\n        location / {\r\n            proxy_pass http://bittroll_webuis;\r\n        }\r\n    }\r\n}\r\n```\r\n\r\nNote: It's a good idea to use nginx caching for certain things (queries, torrent files, etc) if you\r\nexpect high traffic.\r\n\r\n## RESTful API\r\n\r\n### GET /torrents\r\nReturns a JSON object with total count of search results and torrents.\r\n\r\n#### Parameters\r\n* q - Search string (optional)\r\n* offset - Result offset (optional)\r\n* limit - Number of torrents to return (optional)\r\n* category - Restrict to category (optional)\r\n\r\n### POST /torrents\r\n\r\n#### Parameters\r\n* file - The torrent file to be added to the database\r\n\r\n### GET /torrents/\\<info_hash\\>.torrent\r\nReturns the torrent file with the info hash specified.\r\n\r\n### GET /torrents/\\<info_hash\\>/files\r\nReturns the files for the torrent under the specified info hash.\r\n\r\n## Compiling into standalone binary\r\nPyInstaller can be used to generate a stand alone binary of BitTroll. The feature\r\nis still under testing but a build can be involved with `make dist`.\r\n\r\n## License\r\nCopyright (C) 2015  Jacob Zelek <jacob@jacobzelek.com>\r\n\r\nThis program is free software: you can redistribute it and/or modify\r\nit under the terms of the GNU General Public License as published by\r\nthe Free Software Foundation, either version 3 of the License, or\r\n(at your option) any later version.\r\n\r\nThis program is distributed in the hope that it will be useful,\r\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\r\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\r\nGNU General Public License for more details.\r\n\r\nYou should have received a copy of the GNU General Public License\r\nalong with this program.  If not, see <http://www.gnu.org/licenses/>\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}